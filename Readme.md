# Unifying Symbolic Music Arrangement: Track-Aware Reconstruction and Structured Tokenization

This is the code for experiments in the paper *Unifying Symbolic Music Arrangement: Track-Aware Reconstruction and Structured Tokenization*. 

## Structure

    .
    â”œâ”€â”€ baselines               Baseline implementations
    â”œâ”€â”€ dataset_preparation     Prepare dataset for training
    â”œâ”€â”€ evaluations             Functions to evaluate model performance
    â”œâ”€â”€ m2m                     Model training
    â”œâ”€â”€ tests                   Sanity check scripts
    â”œâ”€â”€ utils_arrange           Utility functions for arrangement inference
    â”œâ”€â”€ utils_chord             Utility functions for chord detection
    â”œâ”€â”€ utils_common            Common Utility functions
    â”œâ”€â”€ utils_instrument        Utility functions for instrument
    â”œâ”€â”€ utils_midi              Utility functions for MIDI, including the proposed tokenization
    â””â”€â”€ utils_texture           Utility functions for texture analysis

Most useful scripts are located in the `m2m` directory, containing: 
- Model definition: `m2m_models.py` and `lightning_model.py`.
- Dataset class: `lightning_dataset.py`.
- Pre-train: `pretrain.py`
- Fine-tuning script: `lightning_train.py`
- Testing script: `lightning_test.py`
- Inference (band/piano arrangement): `reinst.py`
- Inference (drum arrangement): `drum_arrange.py`

The hyperparameter of all experiments are saved in `m2m/hparams`.

<!-- ## Results
### Objective Evaluation Results for the Band Arrangement Task

Statistical significance: * for _p_ < 0.05, â€  for _p_ < 0.01, â€¡ for _p_ < 0.001.

| Model                      | I-IOU â†‘      | V-WER â†“     | Note F1 â†‘   | Note<sub>i</sub> F1 â†‘ | Mel F1 â†‘    |
|---------------------------|--------------|-------------|-------------|------------------------|-------------|
| Transformer-VAE           | 97.5         | 35.0        | 49.5        | 40.0                   | 24.7        |
| Transformer w/ REMI+      | 95.0         | 18.2        | 94.4        | 76.0                   | 68.8        |
| Transformer w/ REMI-z     | â€¡99.5        | â€¡9.9        | â€¡**97.8**   | â€¡77.5                  | â€¡77.8       |
| + Pre-training (Ours)     | *_99.8_*     | **7.6**     | *_97.5_*    | **87.0**               | **84.5**    |
| â€“ voice                   | 99.6         | *_17.6_*    | 97.2        | *_84.3_*               | *_81.5_*    |
| â€“ history                 | **100.0**    | *_9.0_*     | 97.6        | 77.4                   | 79.4        |

### Band Arrangement Subjective Evaluation Results

*Fa.* = Faithfulness, *Co.* = Coherence, *In.* = Instrumentation, *Cr.* = Creativity, *Mu.* = Musicality  
Statistical significance: * for _p_ < 0.05, â€  for _p_ < 0.01, â€¡ for _p_ < 0.001.

| Model           | Fa. â†‘ | Co. â†‘ | In. â†‘ | Cr. â†‘ | Mu. â†‘ |
|----------------|--------|--------|--------|--------|--------|
| Rule-Based      | _3.46_ | _3.05_ | _2.89_ | _3.00_ | _3.07_ |
| Transformer-VAE | 2.65   | 2.70   | 2.72   | _3.00_ | 2.72   |
| Ours            | â€¡**3.77** | â€¡**3.47** | â€¡**3.49** | ***3.40** | â€¡**3.47** |
| w/o PT          | 3.19   | 2.82   | 2.86   | 2.93   | 2.75   |

### Piano Reduction Results

*F1* = Note F1 (objective), *Fa.* = Faithfulness, *Co.* = Coherence, *Pl.* = Playability, *Cr.* = Creativity, *Mu.* = Musicality  
Statistical significance: * for _p_ < 0.05, â€  for _p_ < 0.01, â€¡ for _p_ < 0.001.

| Model     | F1 â†‘   | Fa. â†‘       | Co. â†‘       | Pl. â†‘       | Cr. â†‘       | Mu. â†‘       |
|-----------|--------|-------------|-------------|-------------|-------------|-------------|
| Rule-F    | â€“      | **3.93**    | _3.59_      | 3.14        | _2.96_      | _3.34_      |
| Rule-O    | â€“      | 2.75        | 3.49        | **4.07**    | 2.62        | 2.96        |
| UNet      | 58.3   | 2.97        | 2.90        | 3.47        | 2.82        | 2.78        |
| Ours      | **85.5** | â€¡_3.63_    | â€¡**3.64**   | *3.86*      | ***3.14**   | â€¡**3.48**   |
| w/o PT    | _78.4_ | 2.25        | 2.58        | 3.29        | 2.67        | 2.26        |

### Drum Arrangement Results

*F1* = Note F1 (objective), *Comp.* = Compatibility, *Co.* = Coherence, *Tr.* = Phrase Transition, *Cr.* = Creativity, *Mu.* = Musicality  
Statistical significance: * for _p_ < 0.05, â€  for _p_ < 0.01, â€¡ for _p_ < 0.001.

| Model         | F1 â†‘    | Comp. â†‘     | Co. â†‘       | Tr. â†‘         | Cr. â†‘         | Mu. â†‘        |
|---------------|---------|-------------|-------------|---------------|---------------|--------------|
| Ground Truth  | **100.0** | **4.31**    | **4.18**    | _3.36_        | _3.16_        | **3.78**     |
| CA v2         | 20.3    | 3.82        | _4.05_      | 2.86          | 2.58          | 3.19         |
| Ours          | _79.3_  | _3.91_      | 4.03        | â€¡**3.77**     | â€¡**3.27**     | â€ _3.57_      |
| w/o PT        | 1.2     | 2.49        | 2.19        | 2.21          | 2.82          | 2.05         |


### Tokenization Scheme Comparison on Unconditional Generation

*â†“* indicates lower is better.  
$\bar{T}_{\text{bar}}$ = tokens per bar,  
$\bar{T}_{\text{note}}$ = tokens per note,  
$\bar{H}_{\text{bar}}$ = bar-level entropy,  
PPL = perplexity.

| Tokenizer        | ğ‘‡Ì„<sub>bar</sub> â†“ | ğ‘‡Ì„<sub>note</sub> â†“ | ğ»Ì„<sub>bar</sub> â†“ | PPL<sub>note</sub> â†“ | PPL<sub>token</sub> â†“ |
|------------------|--------------------|----------------------|---------------------|-----------------------|------------------------|
| REMI+            | 225.91             | 4.03                 | 41.68               | 116.20                | **3.00**               |
| REMI-z (Ours)    | **151.68**         | **2.77**             | **29.43**           | **84.11**             | 4.50                   | -->



## Prepare Environment
    # Environment
    conda create -n m2m python=3.8
    conda activate m2m

    # Install PyTorch
    pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121

    # Dependencies
    pip install -r requirements.txt   
    
    git clone https://github.com/Sonata165/REMI-z.git
    cd REMI-z
    pip install -r Requirements.txt
    pip install -e .


## Dataset preparation

    cd dataset_preparation

    # For pre-training
    python LAMD_to_remi.py

    # For fine-tuning
    python segment_data.py

## Training and Testing
Use below command for pre-train your own symbolic music generator: 

    python pretrain.py
Use below command to execute fine-tuning:
    
    python lightning_train.py [path/to/hparam]
    
    e.g.,
    python lightning_train.py hparams/elaborator_direct.yaml # our band arrangement model in the paper

After training, use below command for testing to get objective metrics (for voice separation and probing experiments)

    python lightning_test.py [path/to/hparam]

In particular, to obtain the results in the paper

    cd m2m

    # Generative pre-train
    python pretrain.py

    # Non-creative band arrangement for objective evaluation
    python lightning_train.py hparams/band_obj/ours.yaml

    # Band arrangement model
    python lightning_train.py hparams/band_arrange/elaborator.yaml

    # Piano reduction model
    python lightning_train.py hparams/piano_reduction/reduction_dur.yaml

    # Drum arrangement model
    python lightning_train.py hparams/drum_arrange/direct_opd.yaml

## Inference
To inference with models trained by yourself, use below command to arrange existing songs with new instrument set:

    python reinst.py [path/to/hparam]

Use below command to arrange a drum track for a song:

    python drum_arrange.py [path/to/hparam]

To directly use our pretrained model for inference, see tutorial.ipynb for details.


## Mapping from token to represented value
As in the appendix, you can find the mapping from token to their corresponding representing values, for time signature and tempo tokens, in `ts_dict.yaml` and `tempo_dict.yaml`, under the `utils_midi` directory.